{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data in pandas (no parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv('../../mimic3/data/PATIENTS.csv')\n",
    "admissions = pd.read_csv('../../mimic3/data/ADMISSIONS.csv')\n",
    "# icustays = pd.read_csv('../mimic3/data/ICUSTAYS.csv')\n",
    "# servs = pd.read_csv('../mimic3/data/SERVICES.csv')\n",
    "# trans = pd.read_csv('../mimic3/data/TRANSFERS.csv')\n",
    "# drgCodes = pd.read_csv('../mimic3/data/DRGCODES.csv')\n",
    "dias = pd.read_csv('../../mimic3/data/DIAGNOSES_ICD.csv')\n",
    "diag_dict = pd.read_csv('../../mimic3/data/D_ICD_DIAGNOSES.csv')\n",
    "pres = pd.read_csv('../../mimic3/data/PRESCRIPTIONS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ICD9 codes including \"Unspecified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unspicified_codes = diag_dict[diag_dict.SHORT_TITLE.str.contains('NOS')].ICD9_CODE.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ICD9 codes which happened at least 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_values = dias.ICD9_CODE.value_counts().to_frame()\n",
    "freq_codes = code_values.loc[code_values.ICD9_CODE >= 100].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ICD9 codes which happened at least 100 times and excluding codes with \"Unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_codes_ls = list(set(freq_codes) - set(unspicified_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Patients' demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = admissions.drop_duplicates(subset='SUBJECT_ID', keep='last')\n",
    "profiles = profiles[['SUBJECT_ID','INSURANCE','LANGUAGE','RELIGION','MARITAL_STATUS','ETHNICITY']]\n",
    "profs = pd.merge(profiles,patients,how='inner',on='SUBJECT_ID').\\\n",
    "            drop(['ROW_ID','DOB','DOD','DOD_HOSP','DOD_SSN','EXPIRE_FLAG'], axis=1)\n",
    "    \n",
    "profs = profs.fillna('NoneValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pid = profs.SUBJECT_ID\n",
    "profs = profs.drop(['SUBJECT_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Data Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "profs_2 = profs.apply(le.fit_transform)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(profs_2)\n",
    "profs_encode = enc.transform(profs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.DataFrame(profs_encode.todense())\n",
    "profs_df = pd.concat([pid,processed_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(dis1, dis2,profs_df):\n",
    "    \n",
    "    #data preprocessing\n",
    "    pat1 = dias[dias.ICD9_CODE==dis1].SUBJECT_ID.unique()\n",
    "    pat2 = dias[dias.ICD9_CODE==dis2].SUBJECT_ID.unique()\n",
    "    pat1 = list(set(pat1) - set(pat2))\n",
    "    pat1_df = pd.DataFrame({'SUBJECT_ID':pat1})\n",
    "    pat2_df = pd.DataFrame({'SUBJECT_ID':pat2})\n",
    "    \n",
    "    #get patients' one-hot data\n",
    "    profs1 = pd.merge(profs_df,pat1_df,how='inner',on='SUBJECT_ID').drop(['SUBJECT_ID'], axis=1)\n",
    "    profs2 = pd.merge(profs_df,pat2_df,how='inner',on='SUBJECT_ID').drop(['SUBJECT_ID'], axis=1)\n",
    "    profs = pd.concat([profs1,profs2],axis=0)\n",
    "    \n",
    "    #Assign label to each patient\n",
    "    pat1 = pd.DataFrame({'label':np.ones(profs1.shape[0])})\n",
    "    pat2 = pd.DataFrame({'label':np.zeros(profs2.shape[0])})\n",
    "    labels = pd.concat([pat1,pat2],axis=0)\n",
    "    \n",
    "    #data scaling\n",
    "    data = preprocessing.StandardScaler().fit_transform(profs)\n",
    "    \n",
    "    #logistic Classifiction\n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "            model_selection.train_test_split(data, labels, test_size=.2, random_state=42)\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    score = logreg.score(X_test, y_test)\n",
    "   \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    f_score = f1_score(y_test,y_pred)\n",
    "    \n",
    "#     print (\"Disease: {} and {}, patients' number: {} and {}, accuracy:{}, F1 Score:{}\".\\\n",
    "#            format(dis1,dis2,len(profs1),len(profs2),format(score,'.4f'),format(f_score,'.4f')))\n",
    "    return [dis1,dis2,len(profs1),len(profs2),format(score,'.4f'),format(f_score,'.4f')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuepeng/my_py2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "length = len(freq_codes_ls)\n",
    "for idx1 in range(length):\n",
    "    code1 = freq_codes_ls[idx1]\n",
    "    for idx2 in range(idx1+1,length):\n",
    "        code2 = freq_codes_ls[idx2]\n",
    "        results.append(classification(code1, code2,profs_df))\n",
    "results_df = pd.DataFrame(results, columns=['code1','code2','no1','no2','accuracy','f1_score'])  \n",
    "results_df.to_csv('../../mimic3/data/processed_combo.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_1_df = results_df[results_df.f1_score=='1.0000']\n",
    "# f1_1_df.to_csv('../../mimic3/data/processed_combo_f1_1.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_1_gap50_df = results_df[(results_df.f1_score=='1.0000') & (abs(results_df.no1-results_df.no2) <= 100)]\n",
    "# f1_1_gap50.to_csv('../../mimic3/data/processed_combo_f1_1_gap50.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_1_gap50_df = f1_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_1_gap50_desc_df = pd.merge(f1_1_gap50_df,diag_dict,how='left',\\\n",
    "                              left_on='code1',right_on='ICD9_CODE').drop(['ROW_ID','ICD9_CODE'], axis=1)\n",
    "f1_1_gap50_desc_df = f1_1_gap50_desc_df.rename(columns={\"SHORT_TITLE\": \"SHORT_TITLE_1\", \"LONG_TITLE\": \"LONG_TITLE_1\"})\n",
    "\n",
    "f1_1_gap50_desc_df = pd.merge(f1_1_gap50_desc_df,diag_dict,how='left',\\\n",
    "                              left_on='code2',right_on='ICD9_CODE').drop(['ROW_ID','ICD9_CODE'], axis=1)\n",
    "f1_1_gap50_desc_df = f1_1_gap50_desc_df.rename(columns={\"SHORT_TITLE\": \"SHORT_TITLE_2\", \"LONG_TITLE\": \"LONG_TITLE_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1434, 6), (1434, 10))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_1_gap50_df.shape, f1_1_gap50_desc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_1_gap50_desc_df.to_csv('../../mimic3/data/processed_combo_f1_1.csv',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
